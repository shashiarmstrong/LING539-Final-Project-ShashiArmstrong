# -*- coding: utf-8 -*-
"""NLP_Final_Binary.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1s4uUfZErVssgBbs4nyUh4AodGPTWV_gX
"""

from typing import Iterator, Iterable, Tuple, Text, Union

import numpy as np
from sklearn.model_selection import train_test_split
from scipy.sparse import spmatrix
from sklearn.feature_extraction.text import CountVectorizer
from sklearn import preprocessing
import sklearn.linear_model as lm
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import confusion_matrix
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, precision_score, recall_score
from sklearn.metrics import accuracy_score
from sklearn.metrics import classification_report
import matplotlib.pyplot as plt
import seaborn as sns
import csv
import math
import scipy as sp
import scipy.stats


NDArray = Union[np.ndarray, spmatrix]

"""To google drive"""

from google.colab import drive
drive.mount('/content/gdrive')

!cp -r gdrive/MyDrive/NLP_Final /content/

!ls

with open("NLP_Final/trainsubset.csv") as file:
  reader = csv.reader(file)
  list = []
  for line in reader:
    list.append((line[-1], line[-2]))
list = list[1:]
#print (sentimentanalysis.readlines())
#print(list)

texts = [text for _, text in list]

vectorizer = CountVectorizer(ngram_range=(1, 2), min_df=10, max_df=0.8)
vectorizer.fit(texts)

features = vectorizer.transform(texts).toarray()
print(features.shape)

labels = [label for label, _ in list]

le = preprocessing.LabelEncoder()
le.fit(labels)

print(le.classes_)

labelvec = le.transform(labels)

logr = LogisticRegression(fit_intercept= True, max_iter = 4000)
logr.fit(features, labelvec, sample_weight= None)

accuracytrain = logr.score(features, labelvec)
print("Accuracy of Training Subset is {}".format(accuracytrain*100))

"""Test data time!"""

with open("NLP_Final/basetestsubset.csv") as file:
  reader = csv.reader(file)
  listtest = []
  for line in reader:
    listtest.append((line[-1], line[-2]))
listtest = listtest[1:]
#print(listtest)

texts2 = [text for _, text in listtest]
labels2 = [label for label, _ in listtest]

labelvec2 = le.transform(labels2)

features2 = vectorizer.transform(texts2).toarray()
#print(features2.shape)

prediction = logr.predict(features2)
#print(prediction)

conmat = confusion_matrix(labelvec2, prediction)
TNeg, FPos, FNeg, TPos = confusion_matrix(labelvec2, prediction).ravel()
print('True Positive(TPos) = ', TPos)
print('False Positive(FPos) = ', FPos)
print('True Negative(TNeg) = ', TNeg)
print('False Negative(FNeg) = ', FNeg)

plt.figure(figsize=(12,6))
plt.title("Confusion Matrix")
sns.heatmap(conmat, annot=True,fmt='d', cmap='Purples')
plt.ylabel("Actual Values")
plt.xlabel("Predicted Values")
plt.savefig('confusion_matrix.png')

accuracy = (TPos+TNeg) / (TPos+FPos+TNeg+FNeg)
print('Accuracy = {:0.3f}'.format(accuracy))

print('Accuracy for Base Test is {}'.format(accuracy*100))

print(classification_report(labelvec2, prediction))

"""Error Analysis"""

listFNeg = []
listFPos = []
for i in range(len(prediction)):
    if prediction[i] == 0:
        if labelvec2[i] == 1:
            listFPos.append((texts[i], labels2[i]))
    elif prediction[i] == 1:
        if labelvec2[i] == 0:
            listFNeg.append((texts[i], labels2[i]))

print("False Negative: " + str(listFNeg))
print("False Positive: " + str(listFPos))

accuracy =  (TPos+TNeg) /(TPos+FPos+TNeg+FNeg)
print('Accuracy of classification = {:0.3f}'.format(accuracy))

"""P-value caluclations"""

numerator = (.673 - .592)
#print(numerator)
posvalscoresquared = (1- 0.592)**2
#print(posvalscoresquared)
negvalscoresquared = (0-0.592)**2
#print(negvalscoresquared)
sum = (posvalscoresquared * TPos)
#print(sum)
sum2 = (negvalscoresquared * TNeg)
#print(sum2)
numer = (sum + sum2)
#print(numer)
numofrev = 402
numdenom = math.sqrt(numer / numofrev)
#print(denom)
den2 = math.sqrt(numofrev)
#print(den2)
truden = (numdenom/den2)
#print(truden)
zScore = (numerator/truden)
#print(zScore)
pvalue = scipy.stats.norm.sf(abs(zScore))
print(pvalue)

"""# New Section"""
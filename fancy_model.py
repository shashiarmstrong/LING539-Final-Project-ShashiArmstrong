# -*- coding: utf-8 -*-
"""Fancy_Model.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/10MaWAA3sIHn9Z2AN-braevjX36FAdCbm
"""

import pandas as pd
from sklearn.model_selection import train_test_split
import tensorflow as tf
import tensorflow_hub as hub
!pip install tensorflow-text
import tensorflow_text as text

from google.colab import drive
drive.mount('/content/gdrive')

!cp -r gdrive/MyDrive/NLP_Final /content/

!ls

df = pd.read_csv("NLP_Final/fancytest.csv", encoding = "unicode_escape")
df.head()
print(df)

X_train, X_test, y_train, y_test = train_test_split(df['user_review'],df['user_suggestion'], stratify=df['user_suggestion'])
X_train.head(4)

bert_preprocess = hub.KerasLayer("https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3")
bert_encoder = hub.KerasLayer("https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/4")

text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')
preprocessed_text = bert_preprocess(text_input)
outputs = bert_encoder(preprocessed_text)

l = tf.keras.layers.Dropout(0.1, name="dropout")(outputs['pooled_output'])
l = tf.keras.layers.Dense(1, activation='sigmoid', name="output")(l)

model = tf.keras.Model(inputs=[text_input], outputs = [l])

loss = tf.keras.losses.BinaryCrossentropy(from_logits=True)
metrics = tf.metrics.BinaryAccuracy()

model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
model.fit(X_train, y_train, epochs=50, batch_size = 30)

y_predicted = model.predict(X_test)
y_predicted = y_predicted.flatten()
print(y_predicted)